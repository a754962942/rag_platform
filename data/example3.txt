人工智能发展历程与核心概念

1. 起源与早期历史
人工智能（AI）的概念最早可以追溯到古希腊的神话传说。然而，现代AI的真正奠基是在1956年的达特茅斯会议，由约翰·麦卡锡、马文·明斯基等科学家共同提出。
早期研究集中在符号主义AI，即通过规则和逻辑来模拟人类思维。著名的“逻辑理论家”程序和“通用问题求解器”是这一时期的代表。

2. 机器学习与深度学习
机器学习（ML）是AI的一个核心子领域，它允许计算机系统通过数据自动学习和改进，而无需显式编程。
深度学习（DL）是机器学习的一个分支，其灵感来源于人脑的神经网络结构。它利用包含多个层（深度）的神经网络来学习数据的复杂模式。
2012年，AlexNet在ImageNet竞赛中取得突破性胜利，标志着深度学习革命的开始。此后，深度学习在计算机视觉、自然语言处理等领域取得了主导地位。

3. 自然语言处理（NLP）
NLP旨在使计算机能够理解、解释和生成人类语言。
关键技术包括：
词嵌入：如Word2Vec（2013年由谷歌团队提出），将单词映射到高维向量空间，捕获语义关系。
Transformer架构：由谷歌在2017年的论文《Attention Is All You Need》中提出，成为现代NLP的基石。它基于自注意力机制，极大地提升了模型性能。
大语言模型（LLM）：基于Transformer构建，在海量文本数据上训练而成，能够生成流畅的文本、翻译语言、撰写不同风格的文案等。例如GPT系列、BERT和LaMDA。

4. 计算机视觉（CV）
CV使计算机能够从图像和多维数据中“看到”和理解信息。
主要任务包括：图像分类、目标检测（如YOLO算法）、图像分割和面部识别。
生成对抗网络（GANs，2014年由Ian Goodfellow提出）能够生成极其逼真的合成图像。

5. AI伦理与未来挑战
随着AI能力的飞速发展，其伦理和社会影响日益受到关注。
关键挑战包括：算法偏见、数据隐私、自动化带来的就业冲击，以及高级人工智能系统的可控性（AI对齐问题）。
未来方向可能包括具身AI、人工智能与科学发现的结合（如AlphaFold用于蛋白质结构预测），以及朝着更通用的人工智能（AGI）迈进。

关键术语与实体列表：
- 人工智能 (AI)
- 机器学习 (ML)
- 深度学习 (DL)
- 神经网络
- 自然语言处理 (NLP)
- Transformer架构
- 大语言模型 (LLM)
- 计算机视觉 (CV)
- 生成对抗网络 (GANs)
- 达特茅斯会议 (1956)
- 约翰·麦卡锡
- 伊恩·古德费洛
- ImageNet
- AlexNet
- GPT-3
- BERT
- YOLO
- AlphaFold
- AI伦理
- AGI (通用人工智能)